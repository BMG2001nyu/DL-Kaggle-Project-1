{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b563084-86dc-4cfa-8ba5-ef35fc1c2dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f9f249",
   "metadata": {},
   "source": [
    "load_pickle() => is used to read the CIFAR 10 dataset and stores in binary format \n",
    "\n",
    "Data files are loaded in 5 batches, then the images and label's were extracted and were transformed from (C,H,W) to (H,W,C) using transpose(1,2,0)\n",
    "\n",
    "Data augmentation and normalization was done using tensor, mean and standard deviation to stablize and speedup training. \n",
    "\n",
    "Images were randomly cropeed to 32x32 pixels and padding of 4 pixels was added to help in training so that images with slight shifts were also classified correctly \n",
    "\n",
    "DataLoader is used to help the model in learning data in random instead of leaning in a particular order every epoch, 4 worker threads were used to speedup the training process by parallelizing it. \n",
    "\n",
    "Batch size of 256 is used to process many samples of data simultaneously "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa722fd1-d642-4055-a5b9-52f1872fa9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def load_pickle(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='bytes')\n",
    "    return data\n",
    "\n",
    "batch_files = [\n",
    "    \"./data_batch_1\",\n",
    "    \"./data_batch_2\",\n",
    "    \"./data_batch_3\",\n",
    "    \"./data_batch_4\",\n",
    "    \"./data_batch_5\"\n",
    "]\n",
    "\n",
    "train_data, train_labels = [], []\n",
    "for file in batch_files:\n",
    "    batch = load_pickle(file)\n",
    "    train_data.append(batch[b'data'])       \n",
    "    train_labels.extend(batch[b'labels'])\n",
    "\n",
    "train_data = np.vstack(train_data).reshape(-1, 3, 32, 32)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx].transpose(1, 2, 0)  \n",
    "        img = Image.fromarray(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                         std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "trainset = CIFAR10Dataset(train_data, train_labels, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=512, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811e87e7",
   "metadata": {},
   "source": [
    "mish activation function is used to provide smooth gradients and improving the convergence of the network\n",
    "Mish(x) = x . tanh(ln(1+e^x))\n",
    "\n",
    "SE block generates attention weights which scales the output of the convolutional layers\n",
    "\n",
    "Basic block has 2 convolutional layers with batch normalization and mish activation, skip connection is added to allow the flow of gradients solving the vanishing gradient problem\n",
    "\n",
    "\n",
    "Modified ResNet18 - there are 4 major layers to capture different levels of abstraction that is built using stacking the basic blocks\n",
    "\n",
    "Adaptive Average Pooling layers compresses the spatial dimensions into 1x1 per channel - used to summerize each feature map into a single value per channel\n",
    "\n",
    "Normalization is added here as well for stability and speeding up the training \n",
    "\n",
    "\n",
    "While training the model all the transformations and conversions that were used while reading and procressing was added here.\n",
    "\n",
    "Using cross entropy loss to evaluate how well it will align with the prediction \n",
    "\n",
    "SGD is used for stable learning over time \n",
    "\n",
    "Weight decay is used to reguarlize the model, tried with 5e-3, 1e-3\n",
    "\n",
    "CosineAnnealingWarmRestarts is used to dynamically change learning rate based on the loss and number of epochs \n",
    "\n",
    "Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd11f9c-1891-4bd6-871c-00dbecb15cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/100: 100%|██████████| 196/196 [00:15<00:00, 12.72it/s]\n",
      "Testing Epoch 1/100: 100%|██████████| 40/40 [00:00<00:00, 49.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:\n",
      "    Training Loss: 2.0521 | Training Acc: 27.17%\n",
      "    Testing Loss: 1.6034  | Testing Acc: 48.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/100: 100%|██████████| 196/196 [00:12<00:00, 15.29it/s]\n",
      "Testing Epoch 2/100: 100%|██████████| 40/40 [00:00<00:00, 55.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100:\n",
      "    Training Loss: 1.7645 | Training Acc: 41.86%\n",
      "    Testing Loss: 1.4413  | Testing Acc: 56.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/100: 100%|██████████| 196/196 [00:12<00:00, 15.41it/s]\n",
      "Testing Epoch 3/100: 100%|██████████| 40/40 [00:00<00:00, 55.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100:\n",
      "    Training Loss: 1.6096 | Training Acc: 49.60%\n",
      "    Testing Loss: 1.3369  | Testing Acc: 63.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/100: 100%|██████████| 196/196 [00:12<00:00, 15.39it/s]\n",
      "Testing Epoch 4/100: 100%|██████████| 40/40 [00:00<00:00, 56.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100:\n",
      "    Training Loss: 1.5003 | Training Acc: 55.22%\n",
      "    Testing Loss: 1.1873  | Testing Acc: 70.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/100: 100%|██████████| 196/196 [00:12<00:00, 15.22it/s]\n",
      "Testing Epoch 5/100: 100%|██████████| 40/40 [00:00<00:00, 53.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100:\n",
      "    Training Loss: 1.4177 | Training Acc: 59.60%\n",
      "    Testing Loss: 1.1826  | Testing Acc: 70.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/100: 100%|██████████| 196/196 [00:12<00:00, 15.39it/s]\n",
      "Testing Epoch 6/100: 100%|██████████| 40/40 [00:00<00:00, 56.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100:\n",
      "    Training Loss: 1.3543 | Training Acc: 62.63%\n",
      "    Testing Loss: 1.1156  | Testing Acc: 73.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/100: 100%|██████████| 196/196 [00:12<00:00, 15.40it/s]\n",
      "Testing Epoch 7/100: 100%|██████████| 40/40 [00:00<00:00, 55.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100:\n",
      "    Training Loss: 1.3028 | Training Acc: 64.89%\n",
      "    Testing Loss: 1.0513  | Testing Acc: 76.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/100: 100%|██████████| 196/196 [00:12<00:00, 15.48it/s]\n",
      "Testing Epoch 8/100: 100%|██████████| 40/40 [00:00<00:00, 56.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100:\n",
      "    Training Loss: 1.2497 | Training Acc: 67.48%\n",
      "    Testing Loss: 0.9830  | Testing Acc: 80.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/100: 100%|██████████| 196/196 [00:12<00:00, 15.35it/s]\n",
      "Testing Epoch 9/100: 100%|██████████| 40/40 [00:00<00:00, 56.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100:\n",
      "    Training Loss: 1.2047 | Training Acc: 69.35%\n",
      "    Testing Loss: 0.9654  | Testing Acc: 80.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/100: 100%|██████████| 196/196 [00:12<00:00, 15.35it/s]\n",
      "Testing Epoch 10/100: 100%|██████████| 40/40 [00:00<00:00, 56.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100:\n",
      "    Training Loss: 1.1753 | Training Acc: 70.70%\n",
      "    Testing Loss: 0.9365  | Testing Acc: 82.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/100: 100%|██████████| 196/196 [00:12<00:00, 15.31it/s]\n",
      "Testing Epoch 11/100: 100%|██████████| 40/40 [00:00<00:00, 53.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100:\n",
      "    Training Loss: 1.3911 | Training Acc: 60.89%\n",
      "    Testing Loss: 1.1006  | Testing Acc: 74.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/100: 100%|██████████| 196/196 [00:12<00:00, 15.38it/s]\n",
      "Testing Epoch 12/100: 100%|██████████| 40/40 [00:00<00:00, 55.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100:\n",
      "    Training Loss: 1.3424 | Training Acc: 63.08%\n",
      "    Testing Loss: 1.0712  | Testing Acc: 75.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/100: 100%|██████████| 196/196 [00:12<00:00, 15.34it/s]\n",
      "Testing Epoch 13/100: 100%|██████████| 40/40 [00:00<00:00, 53.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100:\n",
      "    Training Loss: 1.3215 | Training Acc: 64.03%\n",
      "    Testing Loss: 1.0379  | Testing Acc: 77.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/100: 100%|██████████| 196/196 [00:12<00:00, 15.39it/s]\n",
      "Testing Epoch 14/100: 100%|██████████| 40/40 [00:00<00:00, 55.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100:\n",
      "    Training Loss: 1.2997 | Training Acc: 64.95%\n",
      "    Testing Loss: 1.0570  | Testing Acc: 76.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/100: 100%|██████████| 196/196 [00:12<00:00, 15.35it/s]\n",
      "Testing Epoch 15/100: 100%|██████████| 40/40 [00:00<00:00, 55.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100:\n",
      "    Training Loss: 1.2824 | Training Acc: 65.92%\n",
      "    Testing Loss: 1.0647  | Testing Acc: 76.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/100: 100%|██████████| 196/196 [00:12<00:00, 15.32it/s]\n",
      "Testing Epoch 16/100: 100%|██████████| 40/40 [00:00<00:00, 55.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100:\n",
      "    Training Loss: 1.2642 | Training Acc: 66.78%\n",
      "    Testing Loss: 1.0264  | Testing Acc: 77.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/100: 100%|██████████| 196/196 [00:12<00:00, 15.31it/s]\n",
      "Testing Epoch 17/100: 100%|██████████| 40/40 [00:00<00:00, 56.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100:\n",
      "    Training Loss: 1.2438 | Training Acc: 68.02%\n",
      "    Testing Loss: 0.9876  | Testing Acc: 79.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/100: 100%|██████████| 196/196 [00:12<00:00, 15.40it/s]\n",
      "Testing Epoch 18/100: 100%|██████████| 40/40 [00:00<00:00, 55.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100:\n",
      "    Training Loss: 1.2288 | Training Acc: 68.49%\n",
      "    Testing Loss: 0.9801  | Testing Acc: 80.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/100: 100%|██████████| 196/196 [00:12<00:00, 15.43it/s]\n",
      "Testing Epoch 19/100: 100%|██████████| 40/40 [00:00<00:00, 55.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100:\n",
      "    Training Loss: 1.2097 | Training Acc: 69.47%\n",
      "    Testing Loss: 0.9884  | Testing Acc: 79.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/100: 100%|██████████| 196/196 [00:12<00:00, 15.37it/s]\n",
      "Testing Epoch 20/100: 100%|██████████| 40/40 [00:00<00:00, 55.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100:\n",
      "    Training Loss: 1.1962 | Training Acc: 69.85%\n",
      "    Testing Loss: 0.9490  | Testing Acc: 81.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21/100: 100%|██████████| 196/196 [00:12<00:00, 15.30it/s]\n",
      "Testing Epoch 21/100: 100%|██████████| 40/40 [00:00<00:00, 54.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100:\n",
      "    Training Loss: 1.1718 | Training Acc: 71.13%\n",
      "    Testing Loss: 0.9437  | Testing Acc: 81.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22/100: 100%|██████████| 196/196 [00:12<00:00, 15.33it/s]\n",
      "Testing Epoch 22/100: 100%|██████████| 40/40 [00:00<00:00, 55.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100:\n",
      "    Training Loss: 1.1569 | Training Acc: 71.70%\n",
      "    Testing Loss: 0.9215  | Testing Acc: 82.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23/100: 100%|██████████| 196/196 [00:12<00:00, 15.36it/s]\n",
      "Testing Epoch 23/100: 100%|██████████| 40/40 [00:00<00:00, 55.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100:\n",
      "    Training Loss: 1.1304 | Training Acc: 73.18%\n",
      "    Testing Loss: 0.9230  | Testing Acc: 82.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24/100: 100%|██████████| 196/196 [00:12<00:00, 15.35it/s]\n",
      "Testing Epoch 24/100: 100%|██████████| 40/40 [00:00<00:00, 56.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100:\n",
      "    Training Loss: 1.1036 | Training Acc: 74.43%\n",
      "    Testing Loss: 0.8865  | Testing Acc: 84.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25/100: 100%|██████████| 196/196 [00:12<00:00, 15.44it/s]\n",
      "Testing Epoch 25/100: 100%|██████████| 40/40 [00:00<00:00, 54.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100:\n",
      "    Training Loss: 1.0820 | Training Acc: 75.38%\n",
      "    Testing Loss: 0.8666  | Testing Acc: 85.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26/100: 100%|██████████| 196/196 [00:12<00:00, 15.44it/s]\n",
      "Testing Epoch 26/100: 100%|██████████| 40/40 [00:00<00:00, 55.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100:\n",
      "    Training Loss: 1.0571 | Training Acc: 76.19%\n",
      "    Testing Loss: 0.8429  | Testing Acc: 86.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27/100: 100%|██████████| 196/196 [00:12<00:00, 15.38it/s]\n",
      "Testing Epoch 27/100: 100%|██████████| 40/40 [00:00<00:00, 55.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100:\n",
      "    Training Loss: 1.0326 | Training Acc: 77.53%\n",
      "    Testing Loss: 0.8271  | Testing Acc: 86.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28/100: 100%|██████████| 196/196 [00:12<00:00, 15.42it/s]\n",
      "Testing Epoch 28/100: 100%|██████████| 40/40 [00:00<00:00, 55.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100:\n",
      "    Training Loss: 1.0152 | Training Acc: 78.33%\n",
      "    Testing Loss: 0.8184  | Testing Acc: 87.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29/100: 100%|██████████| 196/196 [00:12<00:00, 15.39it/s]\n",
      "Testing Epoch 29/100: 100%|██████████| 40/40 [00:00<00:00, 55.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100:\n",
      "    Training Loss: 1.0008 | Training Acc: 79.10%\n",
      "    Testing Loss: 0.8069  | Testing Acc: 87.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30/100: 100%|██████████| 196/196 [00:12<00:00, 15.38it/s]\n",
      "Testing Epoch 30/100: 100%|██████████| 40/40 [00:00<00:00, 53.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100:\n",
      "    Training Loss: 0.9955 | Training Acc: 79.52%\n",
      "    Testing Loss: 0.8041  | Testing Acc: 87.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31/100: 100%|██████████| 196/196 [00:12<00:00, 15.36it/s]\n",
      "Testing Epoch 31/100: 100%|██████████| 40/40 [00:00<00:00, 55.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100:\n",
      "    Training Loss: 1.2981 | Training Acc: 65.21%\n",
      "    Testing Loss: 1.0259  | Testing Acc: 77.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32/100: 100%|██████████| 196/196 [00:12<00:00, 15.31it/s]\n",
      "Testing Epoch 32/100: 100%|██████████| 40/40 [00:00<00:00, 54.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100:\n",
      "    Training Loss: 1.2489 | Training Acc: 67.55%\n",
      "    Testing Loss: 0.9789  | Testing Acc: 80.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33/100: 100%|██████████| 196/196 [00:12<00:00, 15.37it/s]\n",
      "Testing Epoch 33/100: 100%|██████████| 40/40 [00:00<00:00, 55.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100:\n",
      "    Training Loss: 1.2271 | Training Acc: 68.34%\n",
      "    Testing Loss: 0.9902  | Testing Acc: 79.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34/100: 100%|██████████| 196/196 [00:12<00:00, 15.43it/s]\n",
      "Testing Epoch 34/100: 100%|██████████| 40/40 [00:00<00:00, 56.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100:\n",
      "    Training Loss: 1.2245 | Training Acc: 68.73%\n",
      "    Testing Loss: 1.0179  | Testing Acc: 78.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35/100: 100%|██████████| 196/196 [00:12<00:00, 15.35it/s]\n",
      "Testing Epoch 35/100: 100%|██████████| 40/40 [00:00<00:00, 55.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100:\n",
      "    Training Loss: 1.2132 | Training Acc: 69.14%\n",
      "    Testing Loss: 0.9993  | Testing Acc: 78.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36/100: 100%|██████████| 196/196 [00:12<00:00, 15.43it/s]\n",
      "Testing Epoch 36/100: 100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100:\n",
      "    Training Loss: 1.2072 | Training Acc: 69.49%\n",
      "    Testing Loss: 0.9852  | Testing Acc: 79.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37/100: 100%|██████████| 196/196 [00:12<00:00, 15.12it/s]\n",
      "Testing Epoch 37/100: 100%|██████████| 40/40 [00:00<00:00, 55.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100:\n",
      "    Training Loss: 1.2009 | Training Acc: 69.63%\n",
      "    Testing Loss: 0.9698  | Testing Acc: 79.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38/100: 100%|██████████| 196/196 [00:12<00:00, 15.17it/s]\n",
      "Testing Epoch 38/100: 100%|██████████| 40/40 [00:00<00:00, 52.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100:\n",
      "    Training Loss: 1.1826 | Training Acc: 70.61%\n",
      "    Testing Loss: 0.9492  | Testing Acc: 81.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39/100: 100%|██████████| 196/196 [00:12<00:00, 15.33it/s]\n",
      "Testing Epoch 39/100: 100%|██████████| 40/40 [00:00<00:00, 56.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100:\n",
      "    Training Loss: 1.1851 | Training Acc: 70.51%\n",
      "    Testing Loss: 1.0109  | Testing Acc: 78.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40/100: 100%|██████████| 196/196 [00:12<00:00, 15.38it/s]\n",
      "Testing Epoch 40/100: 100%|██████████| 40/40 [00:00<00:00, 53.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100:\n",
      "    Training Loss: 1.1739 | Training Acc: 71.00%\n",
      "    Testing Loss: 1.0003  | Testing Acc: 79.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41/100: 100%|██████████| 196/196 [00:13<00:00, 15.02it/s]\n",
      "Testing Epoch 41/100: 100%|██████████| 40/40 [00:00<00:00, 54.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100:\n",
      "    Training Loss: 1.1656 | Training Acc: 71.19%\n",
      "    Testing Loss: 0.9182  | Testing Acc: 82.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42/100: 100%|██████████| 196/196 [00:13<00:00, 14.86it/s]\n",
      "Testing Epoch 42/100: 100%|██████████| 40/40 [00:00<00:00, 53.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100:\n",
      "    Training Loss: 1.1523 | Training Acc: 72.14%\n",
      "    Testing Loss: 0.9318  | Testing Acc: 81.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43/100: 100%|██████████| 196/196 [00:12<00:00, 15.37it/s]\n",
      "Testing Epoch 43/100: 100%|██████████| 40/40 [00:00<00:00, 56.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100:\n",
      "    Training Loss: 1.1478 | Training Acc: 71.94%\n",
      "    Testing Loss: 0.9272  | Testing Acc: 81.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44/100: 100%|██████████| 196/196 [00:12<00:00, 15.33it/s]\n",
      "Testing Epoch 44/100: 100%|██████████| 40/40 [00:00<00:00, 55.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100:\n",
      "    Training Loss: 1.1384 | Training Acc: 72.50%\n",
      "    Testing Loss: 0.9231  | Testing Acc: 82.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45/100: 100%|██████████| 196/196 [00:12<00:00, 15.38it/s]\n",
      "Testing Epoch 45/100: 100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100:\n",
      "    Training Loss: 1.1300 | Training Acc: 72.92%\n",
      "    Testing Loss: 0.9289  | Testing Acc: 81.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46/100: 100%|██████████| 196/196 [00:12<00:00, 15.44it/s]\n",
      "Testing Epoch 46/100: 100%|██████████| 40/40 [00:00<00:00, 55.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100:\n",
      "    Training Loss: 1.1224 | Training Acc: 73.39%\n",
      "    Testing Loss: 0.9081  | Testing Acc: 83.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47/100: 100%|██████████| 196/196 [00:13<00:00, 14.94it/s]\n",
      "Testing Epoch 47/100: 100%|██████████| 40/40 [00:00<00:00, 53.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100:\n",
      "    Training Loss: 1.1152 | Training Acc: 73.49%\n",
      "    Testing Loss: 0.8998  | Testing Acc: 83.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48/100: 100%|██████████| 196/196 [00:13<00:00, 14.90it/s]\n",
      "Testing Epoch 48/100: 100%|██████████| 40/40 [00:00<00:00, 55.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100:\n",
      "    Training Loss: 1.1016 | Training Acc: 74.14%\n",
      "    Testing Loss: 0.8911  | Testing Acc: 83.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49/100: 100%|██████████| 196/196 [00:12<00:00, 15.12it/s]\n",
      "Testing Epoch 49/100: 100%|██████████| 40/40 [00:00<00:00, 55.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100:\n",
      "    Training Loss: 1.0935 | Training Acc: 74.48%\n",
      "    Testing Loss: 0.8900  | Testing Acc: 83.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50/100: 100%|██████████| 196/196 [00:12<00:00, 15.16it/s]\n",
      "Testing Epoch 50/100: 100%|██████████| 40/40 [00:00<00:00, 55.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100:\n",
      "    Training Loss: 1.0862 | Training Acc: 74.82%\n",
      "    Testing Loss: 0.8698  | Testing Acc: 84.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 51/100: 100%|██████████| 196/196 [00:12<00:00, 15.32it/s]\n",
      "Testing Epoch 51/100: 100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100:\n",
      "    Training Loss: 1.0723 | Training Acc: 75.50%\n",
      "    Testing Loss: 0.8659  | Testing Acc: 84.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 52/100: 100%|██████████| 196/196 [00:12<00:00, 15.34it/s]\n",
      "Testing Epoch 52/100: 100%|██████████| 40/40 [00:00<00:00, 55.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100:\n",
      "    Training Loss: 1.0725 | Training Acc: 75.39%\n",
      "    Testing Loss: 0.8706  | Testing Acc: 84.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53/100: 100%|██████████| 196/196 [00:12<00:00, 15.38it/s]\n",
      "Testing Epoch 53/100: 100%|██████████| 40/40 [00:00<00:00, 55.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100:\n",
      "    Training Loss: 1.0585 | Training Acc: 76.25%\n",
      "    Testing Loss: 0.8572  | Testing Acc: 85.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 54/100: 100%|██████████| 196/196 [00:12<00:00, 15.38it/s]\n",
      "Testing Epoch 54/100: 100%|██████████| 40/40 [00:00<00:00, 55.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100:\n",
      "    Training Loss: 1.0470 | Training Acc: 76.69%\n",
      "    Testing Loss: 0.8521  | Testing Acc: 85.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 55/100: 100%|██████████| 196/196 [00:12<00:00, 15.39it/s]\n",
      "Testing Epoch 55/100: 100%|██████████| 40/40 [00:00<00:00, 55.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100:\n",
      "    Training Loss: 1.0341 | Training Acc: 77.19%\n",
      "    Testing Loss: 0.8316  | Testing Acc: 86.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 56/100: 100%|██████████| 196/196 [00:12<00:00, 15.35it/s]\n",
      "Testing Epoch 56/100: 100%|██████████| 40/40 [00:00<00:00, 55.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100:\n",
      "    Training Loss: 1.0198 | Training Acc: 77.74%\n",
      "    Testing Loss: 0.8165  | Testing Acc: 86.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 57/100: 100%|██████████| 196/196 [00:13<00:00, 14.75it/s]\n",
      "Testing Epoch 57/100: 100%|██████████| 40/40 [00:00<00:00, 54.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100:\n",
      "    Training Loss: 1.0129 | Training Acc: 78.04%\n",
      "    Testing Loss: 0.8135  | Testing Acc: 86.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 58/100: 100%|██████████| 196/196 [00:12<00:00, 15.17it/s]\n",
      "Testing Epoch 58/100: 100%|██████████| 40/40 [00:00<00:00, 56.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100:\n",
      "    Training Loss: 0.9983 | Training Acc: 78.82%\n",
      "    Testing Loss: 0.8070  | Testing Acc: 87.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 59/100: 100%|██████████| 196/196 [00:12<00:00, 15.38it/s]\n",
      "Testing Epoch 59/100: 100%|██████████| 40/40 [00:00<00:00, 55.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100:\n",
      "    Training Loss: 0.9901 | Training Acc: 78.97%\n",
      "    Testing Loss: 0.7921  | Testing Acc: 87.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 60/100: 100%|██████████| 196/196 [00:12<00:00, 15.33it/s]\n",
      "Testing Epoch 60/100: 100%|██████████| 40/40 [00:00<00:00, 55.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100:\n",
      "    Training Loss: 0.9720 | Training Acc: 79.87%\n",
      "    Testing Loss: 0.7804  | Testing Acc: 88.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 61/100: 100%|██████████| 196/196 [00:12<00:00, 15.33it/s]\n",
      "Testing Epoch 61/100: 100%|██████████| 40/40 [00:00<00:00, 54.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100:\n",
      "    Training Loss: 0.9607 | Training Acc: 80.60%\n",
      "    Testing Loss: 0.7745  | Testing Acc: 88.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 62/100: 100%|██████████| 196/196 [00:12<00:00, 15.36it/s]\n",
      "Testing Epoch 62/100: 100%|██████████| 40/40 [00:00<00:00, 54.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100:\n",
      "    Training Loss: 0.9480 | Training Acc: 80.83%\n",
      "    Testing Loss: 0.7750  | Testing Acc: 88.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 63/100: 100%|██████████| 196/196 [00:12<00:00, 15.36it/s]\n",
      "Testing Epoch 63/100: 100%|██████████| 40/40 [00:00<00:00, 56.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100:\n",
      "    Training Loss: 0.9297 | Training Acc: 82.00%\n",
      "    Testing Loss: 0.7629  | Testing Acc: 89.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 64/100: 100%|██████████| 196/196 [00:12<00:00, 15.33it/s]\n",
      "Testing Epoch 64/100: 100%|██████████| 40/40 [00:00<00:00, 55.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100:\n",
      "    Training Loss: 0.9271 | Training Acc: 82.02%\n",
      "    Testing Loss: 0.7495  | Testing Acc: 89.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 65/100: 100%|██████████| 196/196 [00:12<00:00, 15.33it/s]\n",
      "Testing Epoch 65/100: 100%|██████████| 40/40 [00:00<00:00, 54.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100:\n",
      "    Training Loss: 0.9172 | Training Acc: 82.47%\n",
      "    Testing Loss: 0.7411  | Testing Acc: 90.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 66/100: 100%|██████████| 196/196 [00:12<00:00, 15.38it/s]\n",
      "Testing Epoch 66/100: 100%|██████████| 40/40 [00:00<00:00, 54.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100:\n",
      "    Training Loss: 0.9018 | Training Acc: 83.16%\n",
      "    Testing Loss: 0.7336  | Testing Acc: 90.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 67/100: 100%|██████████| 196/196 [00:12<00:00, 15.35it/s]\n",
      "Testing Epoch 67/100: 100%|██████████| 40/40 [00:00<00:00, 55.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100:\n",
      "    Training Loss: 0.8954 | Training Acc: 83.30%\n",
      "    Testing Loss: 0.7302  | Testing Acc: 90.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 68/100: 100%|██████████| 196/196 [00:12<00:00, 15.35it/s]\n",
      "Testing Epoch 68/100: 100%|██████████| 40/40 [00:00<00:00, 55.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100:\n",
      "    Training Loss: 0.8900 | Training Acc: 83.68%\n",
      "    Testing Loss: 0.7291  | Testing Acc: 90.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 69/100: 100%|██████████| 196/196 [00:12<00:00, 15.39it/s]\n",
      "Testing Epoch 69/100: 100%|██████████| 40/40 [00:00<00:00, 55.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100:\n",
      "    Training Loss: 0.8847 | Training Acc: 84.06%\n",
      "    Testing Loss: 0.7254  | Testing Acc: 90.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 70/100: 100%|██████████| 196/196 [00:12<00:00, 15.44it/s]\n",
      "Testing Epoch 70/100: 100%|██████████| 40/40 [00:00<00:00, 47.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100:\n",
      "    Training Loss: 0.8827 | Training Acc: 84.06%\n",
      "    Testing Loss: 0.7249  | Testing Acc: 90.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 71/100: 100%|██████████| 196/196 [00:12<00:00, 15.33it/s]\n",
      "Testing Epoch 71/100: 100%|██████████| 40/40 [00:00<00:00, 56.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100:\n",
      "    Training Loss: 1.2394 | Training Acc: 67.97%\n",
      "    Testing Loss: 1.0006  | Testing Acc: 78.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 72/100: 100%|██████████| 196/196 [00:12<00:00, 15.41it/s]\n",
      "Testing Epoch 72/100: 100%|██████████| 40/40 [00:00<00:00, 56.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100:\n",
      "    Training Loss: 1.1780 | Training Acc: 70.37%\n",
      "    Testing Loss: 0.9420  | Testing Acc: 81.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 73/100: 100%|██████████| 196/196 [00:12<00:00, 15.42it/s]\n",
      "Testing Epoch 73/100: 100%|██████████| 40/40 [00:00<00:00, 55.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100:\n",
      "    Training Loss: 1.1540 | Training Acc: 71.62%\n",
      "    Testing Loss: 0.9493  | Testing Acc: 80.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 74/100: 100%|██████████| 196/196 [00:12<00:00, 15.38it/s]\n",
      "Testing Epoch 74/100: 100%|██████████| 40/40 [00:00<00:00, 54.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100:\n",
      "    Training Loss: 1.1440 | Training Acc: 72.14%\n",
      "    Testing Loss: 0.9316  | Testing Acc: 81.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 75/100: 100%|██████████| 196/196 [00:12<00:00, 15.37it/s]\n",
      "Testing Epoch 75/100: 100%|██████████| 40/40 [00:00<00:00, 55.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100:\n",
      "    Training Loss: 1.1383 | Training Acc: 72.50%\n",
      "    Testing Loss: 0.9092  | Testing Acc: 82.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 76/100: 100%|██████████| 196/196 [00:12<00:00, 15.42it/s]\n",
      "Testing Epoch 76/100: 100%|██████████| 40/40 [00:00<00:00, 55.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100:\n",
      "    Training Loss: 1.1366 | Training Acc: 72.41%\n",
      "    Testing Loss: 0.8970  | Testing Acc: 83.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 77/100: 100%|██████████| 196/196 [00:12<00:00, 15.39it/s]\n",
      "Testing Epoch 77/100: 100%|██████████| 40/40 [00:00<00:00, 55.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100:\n",
      "    Training Loss: 1.1288 | Training Acc: 72.80%\n",
      "    Testing Loss: 0.9239  | Testing Acc: 82.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 78/100: 100%|██████████| 196/196 [00:12<00:00, 15.34it/s]\n",
      "Testing Epoch 78/100: 100%|██████████| 40/40 [00:00<00:00, 55.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100:\n",
      "    Training Loss: 1.1270 | Training Acc: 72.92%\n",
      "    Testing Loss: 0.9391  | Testing Acc: 81.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 79/100: 100%|██████████| 196/196 [00:12<00:00, 15.24it/s]\n",
      "Testing Epoch 79/100: 100%|██████████| 40/40 [00:00<00:00, 55.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100:\n",
      "    Training Loss: 1.1212 | Training Acc: 73.22%\n",
      "    Testing Loss: 0.8705  | Testing Acc: 84.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 80/100: 100%|██████████| 196/196 [00:12<00:00, 15.41it/s]\n",
      "Testing Epoch 80/100: 100%|██████████| 40/40 [00:00<00:00, 55.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100:\n",
      "    Training Loss: 1.1172 | Training Acc: 73.33%\n",
      "    Testing Loss: 0.9025  | Testing Acc: 83.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 81/100: 100%|██████████| 196/196 [00:12<00:00, 15.42it/s]\n",
      "Testing Epoch 81/100: 100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100:\n",
      "    Training Loss: 1.1173 | Training Acc: 73.38%\n",
      "    Testing Loss: 0.8970  | Testing Acc: 83.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 82/100: 100%|██████████| 196/196 [00:12<00:00, 15.39it/s]\n",
      "Testing Epoch 82/100: 100%|██████████| 40/40 [00:00<00:00, 56.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100:\n",
      "    Training Loss: 1.1160 | Training Acc: 73.39%\n",
      "    Testing Loss: 0.8727  | Testing Acc: 84.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 83/100: 100%|██████████| 196/196 [00:13<00:00, 14.84it/s]\n",
      "Testing Epoch 83/100: 100%|██████████| 40/40 [00:00<00:00, 56.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100:\n",
      "    Training Loss: 1.1103 | Training Acc: 73.60%\n",
      "    Testing Loss: 0.9221  | Testing Acc: 82.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 84/100: 100%|██████████| 196/196 [00:12<00:00, 15.36it/s]\n",
      "Testing Epoch 84/100: 100%|██████████| 40/40 [00:00<00:00, 56.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100:\n",
      "    Training Loss: 1.1136 | Training Acc: 73.55%\n",
      "    Testing Loss: 0.8643  | Testing Acc: 84.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 85/100:  67%|██████▋   | 131/196 [00:08<00:04, 14.61it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.tanh(F.softplus(x))\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // reduction, 1),\n",
    "            Mish(),\n",
    "            nn.Conv2d(channels // reduction, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.se(x)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.se = SEBlock(planes)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = Mish()(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.se(out)\n",
    "        out += self.shortcut(x)\n",
    "        return Mish()(out)\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, dropout_prob=0.5):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_planes = 32\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(dropout_prob)  \n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = Mish()(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = self.dropout(out) \n",
    "        out = torch.flatten(out, 1)\n",
    "        return self.fc(out)\n",
    "\n",
    "def train():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.AutoAugment(),  \n",
    "        transforms.ToTensor(),         \n",
    "        transforms.RandomErasing(),     \n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "    \n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "    \n",
    "    trainset = CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "    trainloader = DataLoader(trainset, batch_size=256, shuffle=True, num_workers=4)\n",
    "    \n",
    "    testset = CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "    testloader = DataLoader(testset, batch_size=256, shuffle=False, num_workers=4)\n",
    "    \n",
    "    model = ResNet18(BasicBlock, [2, 2, 2, 2]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-3)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "    \n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(trainloader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_train += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        avg_train_loss = train_loss / total_train\n",
    "        train_acc = 100. * train_correct / total_train\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        total_test = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(testloader, desc=f\"Testing Epoch {epoch+1}/{num_epochs}\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_test += labels.size(0)\n",
    "                test_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        avg_test_loss = test_loss / total_test\n",
    "        test_acc = 100. * test_correct / total_test\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"    Training Loss: {avg_train_loss:.4f} | Training Acc: {train_acc:.2f}%\")\n",
    "        print(f\"    Testing Loss: {avg_test_loss:.4f}  | Testing Acc: {test_acc:.2f}%\")\n",
    "        torch.save(model.state_dict(), \"1optimized_resnet18.pth\")\n",
    "    \n",
    "    print(\"\\n Model Summary After Training:\")\n",
    "    summary(model, (3, 32, 32))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f842b",
   "metadata": {},
   "source": [
    "Code to Create the submissions.csv file after unpickling the nolabel data and running an inference on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0a75f3f-0c2b-43aa-b6f8-3549906f4a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Test set loaded: (10000, 32, 32, 3)\n",
      "Inference completed!\n",
      "submission.csv generated.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = ResNet18(BasicBlock, [2, 2, 2, 2]).to(device)\n",
    "state_dict = torch.load(\"optimized_resnet18.pth\", map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()  \n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "def load_cifar_batch(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        batch = pickle.load(fo, encoding='bytes')\n",
    "    return batch\n",
    "\n",
    "file_path = \"./cifar_test_nolabel.pkl\"\n",
    "cifar10_batch = load_cifar_batch(file_path)\n",
    "\n",
    "test_images = cifar10_batch[b'data']  \n",
    "image_ids = cifar10_batch[b'ids'] \n",
    "\n",
    "print(f\"Test set loaded: {test_images.shape}\")\n",
    "\n",
    "test_images = torch.tensor(test_images, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n",
    "transform = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n",
    "test_images = torch.stack([transform(img) for img in test_images])\n",
    "\n",
    "\n",
    "test_images = test_images.to(device)  \n",
    "batch_size = 64  \n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_images), batch_size):\n",
    "        batch = test_images[i:i + batch_size]  \n",
    "        outputs = model(batch)  \n",
    "        _, predicted_labels = torch.max(outputs, 1) \n",
    "        predictions.extend(predicted_labels.cpu().numpy())  \n",
    "\n",
    "print(\"Inference completed!\")\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    \"ID\": image_ids,\n",
    "    \"Labels\": predictions\n",
    "})\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"submission.csv generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b299f09-6e9b-4dce-af53-15bfc2088401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Labels\n",
      "0   0       6\n",
      "1   1       1\n",
      "2   2       8\n",
      "3   3       6\n",
      "4   4       9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./submission.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4d57e3",
   "metadata": {},
   "source": [
    "Code to check the distribution of labels for a total of 10,000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d456a19c-c5db-4371-86e8-5c0b60624f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique labels: 10\n",
      "Labels\n",
      "3    1207\n",
      "2    1112\n",
      "8    1079\n",
      "1    1060\n",
      "5    1004\n",
      "7     989\n",
      "4     943\n",
      "6     904\n",
      "9     883\n",
      "0     819\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_labels = df['Labels'].nunique()\n",
    "print(f\"Total unique labels: {unique_labels}\")\n",
    "\n",
    "label_counts = df['Labels'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5773705f",
   "metadata": {},
   "source": [
    "Code to check the accuracy of the model trained using the test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "218c1f64-0b1d-47c9-a89d-bc626ddaedd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Test set loaded: (10000, 3072)\n",
      "Accuracy on test set: 92.72%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import pickle\n",
    "\n",
    "def load_cifar_batch(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        batch = pickle.load(fo, encoding='bytes')\n",
    "    return batch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = ResNet18(BasicBlock, [2, 2, 2, 2]).to(device)\n",
    "state_dict = torch.load(\"optimized_resnet18.pth\", map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()  \n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "file_path = \"test_batch\"  \n",
    "cifar_batch = load_cifar_batch(file_path)\n",
    "\n",
    "test_images = cifar_batch[b'data']   \n",
    "true_labels = cifar_batch[b'labels']  \n",
    "\n",
    "print(f\"Test set loaded: {test_images.shape}\")\n",
    "\n",
    "if test_images.shape[1] == 3072:\n",
    "    test_images = test_images.reshape(-1, 3, 32, 32)\n",
    "elif test_images.shape[1] == 32:\n",
    "    test_images = torch.tensor(test_images, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n",
    "else:\n",
    "    test_images = torch.tensor(test_images, dtype=torch.float32) / 255.0\n",
    "\n",
    "if not isinstance(test_images, torch.Tensor):\n",
    "    test_images = torch.tensor(test_images, dtype=torch.float32) / 255.0\n",
    "\n",
    "if test_images.shape[1] != 3:\n",
    "    test_images = test_images.permute(0, 3, 1, 2)\n",
    "\n",
    "normalize_transform = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                                             std=[0.2470, 0.2435, 0.2616])\n",
    "\n",
    "test_images = torch.stack([normalize_transform(img) for img in test_images])\n",
    "test_images = test_images.to(device)\n",
    "\n",
    "true_labels = torch.tensor(true_labels, dtype=torch.long).to(device)\n",
    "\n",
    "batch_size = 64\n",
    "total = test_images.size(0)\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, total, batch_size):\n",
    "        batch = test_images[i:i+batch_size]\n",
    "        outputs = model(batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == true_labels[i:i+batch_size]).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on test set: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c09efd",
   "metadata": {},
   "source": [
    "Code to Count the number of parameters = 4.5 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d38d38-d16f-4a9a-be25-08a84b503007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/200: 100%|██████████| 196/196 [00:15<00:00, 12.88it/s]\n",
      "Testing Epoch 1/200: 100%|██████████| 40/40 [00:00<00:00, 49.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200:\n",
      "    Training Loss: 0.7354 | Training Acc: 90.15%\n",
      "    Testing Loss: 0.6711  | Testing Acc: 92.73%\n",
      "\n",
      " Model Summary After Training:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             864\n",
      "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
      "            Conv2d-3           [-1, 32, 32, 32]           9,216\n",
      "       BatchNorm2d-4           [-1, 32, 32, 32]              64\n",
      "            Conv2d-5           [-1, 32, 32, 32]           9,216\n",
      "       BatchNorm2d-6           [-1, 32, 32, 32]              64\n",
      " AdaptiveAvgPool2d-7             [-1, 32, 1, 1]               0\n",
      "            Conv2d-8              [-1, 2, 1, 1]              66\n",
      "              Mish-9              [-1, 2, 1, 1]               0\n",
      "           Conv2d-10             [-1, 32, 1, 1]              96\n",
      "          Sigmoid-11             [-1, 32, 1, 1]               0\n",
      "          SEBlock-12           [-1, 32, 32, 32]               0\n",
      "       BasicBlock-13           [-1, 32, 32, 32]               0\n",
      "           Conv2d-14           [-1, 32, 32, 32]           9,216\n",
      "      BatchNorm2d-15           [-1, 32, 32, 32]              64\n",
      "           Conv2d-16           [-1, 32, 32, 32]           9,216\n",
      "      BatchNorm2d-17           [-1, 32, 32, 32]              64\n",
      "AdaptiveAvgPool2d-18             [-1, 32, 1, 1]               0\n",
      "           Conv2d-19              [-1, 2, 1, 1]              66\n",
      "             Mish-20              [-1, 2, 1, 1]               0\n",
      "           Conv2d-21             [-1, 32, 1, 1]              96\n",
      "          Sigmoid-22             [-1, 32, 1, 1]               0\n",
      "          SEBlock-23           [-1, 32, 32, 32]               0\n",
      "       BasicBlock-24           [-1, 32, 32, 32]               0\n",
      "           Conv2d-25           [-1, 64, 16, 16]          18,432\n",
      "      BatchNorm2d-26           [-1, 64, 16, 16]             128\n",
      "           Conv2d-27           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-28           [-1, 64, 16, 16]             128\n",
      "AdaptiveAvgPool2d-29             [-1, 64, 1, 1]               0\n",
      "           Conv2d-30              [-1, 4, 1, 1]             260\n",
      "             Mish-31              [-1, 4, 1, 1]               0\n",
      "           Conv2d-32             [-1, 64, 1, 1]             320\n",
      "          Sigmoid-33             [-1, 64, 1, 1]               0\n",
      "          SEBlock-34           [-1, 64, 16, 16]               0\n",
      "           Conv2d-35           [-1, 64, 16, 16]           2,048\n",
      "      BatchNorm2d-36           [-1, 64, 16, 16]             128\n",
      "       BasicBlock-37           [-1, 64, 16, 16]               0\n",
      "           Conv2d-38           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-39           [-1, 64, 16, 16]             128\n",
      "           Conv2d-40           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-41           [-1, 64, 16, 16]             128\n",
      "AdaptiveAvgPool2d-42             [-1, 64, 1, 1]               0\n",
      "           Conv2d-43              [-1, 4, 1, 1]             260\n",
      "             Mish-44              [-1, 4, 1, 1]               0\n",
      "           Conv2d-45             [-1, 64, 1, 1]             320\n",
      "          Sigmoid-46             [-1, 64, 1, 1]               0\n",
      "          SEBlock-47           [-1, 64, 16, 16]               0\n",
      "       BasicBlock-48           [-1, 64, 16, 16]               0\n",
      "           Conv2d-49            [-1, 256, 8, 8]         147,456\n",
      "      BatchNorm2d-50            [-1, 256, 8, 8]             512\n",
      "           Conv2d-51            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-52            [-1, 256, 8, 8]             512\n",
      "AdaptiveAvgPool2d-53            [-1, 256, 1, 1]               0\n",
      "           Conv2d-54             [-1, 16, 1, 1]           4,112\n",
      "             Mish-55             [-1, 16, 1, 1]               0\n",
      "           Conv2d-56            [-1, 256, 1, 1]           4,352\n",
      "          Sigmoid-57            [-1, 256, 1, 1]               0\n",
      "          SEBlock-58            [-1, 256, 8, 8]               0\n",
      "           Conv2d-59            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-60            [-1, 256, 8, 8]             512\n",
      "       BasicBlock-61            [-1, 256, 8, 8]               0\n",
      "           Conv2d-62            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-63            [-1, 256, 8, 8]             512\n",
      "           Conv2d-64            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-65            [-1, 256, 8, 8]             512\n",
      "AdaptiveAvgPool2d-66            [-1, 256, 1, 1]               0\n",
      "           Conv2d-67             [-1, 16, 1, 1]           4,112\n",
      "             Mish-68             [-1, 16, 1, 1]               0\n",
      "           Conv2d-69            [-1, 256, 1, 1]           4,352\n",
      "          Sigmoid-70            [-1, 256, 1, 1]               0\n",
      "          SEBlock-71            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-72            [-1, 256, 8, 8]               0\n",
      "           Conv2d-73            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-74            [-1, 256, 4, 4]             512\n",
      "           Conv2d-75            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-76            [-1, 256, 4, 4]             512\n",
      "AdaptiveAvgPool2d-77            [-1, 256, 1, 1]               0\n",
      "           Conv2d-78             [-1, 16, 1, 1]           4,112\n",
      "             Mish-79             [-1, 16, 1, 1]               0\n",
      "           Conv2d-80            [-1, 256, 1, 1]           4,352\n",
      "          Sigmoid-81            [-1, 256, 1, 1]               0\n",
      "          SEBlock-82            [-1, 256, 4, 4]               0\n",
      "           Conv2d-83            [-1, 256, 4, 4]          65,536\n",
      "      BatchNorm2d-84            [-1, 256, 4, 4]             512\n",
      "       BasicBlock-85            [-1, 256, 4, 4]               0\n",
      "           Conv2d-86            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-87            [-1, 256, 4, 4]             512\n",
      "           Conv2d-88            [-1, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
      "AdaptiveAvgPool2d-90            [-1, 256, 1, 1]               0\n",
      "           Conv2d-91             [-1, 16, 1, 1]           4,112\n",
      "             Mish-92             [-1, 16, 1, 1]               0\n",
      "           Conv2d-93            [-1, 256, 1, 1]           4,352\n",
      "          Sigmoid-94            [-1, 256, 1, 1]               0\n",
      "          SEBlock-95            [-1, 256, 4, 4]               0\n",
      "       BasicBlock-96            [-1, 256, 4, 4]               0\n",
      "AdaptiveAvgPool2d-97            [-1, 256, 1, 1]               0\n",
      "           Linear-98                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 4,570,934\n",
      "Trainable params: 4,570,934\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 7.47\n",
      "Params size (MB): 17.44\n",
      "Estimated Total Size (MB): 24.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.tanh(F.softplus(x))\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // reduction, 1),\n",
    "            Mish(),\n",
    "            nn.Conv2d(channels // reduction, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.se(x)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.se = SEBlock(planes)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = Mish()(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.se(out)\n",
    "        out += self.shortcut(x)\n",
    "        return Mish()(out)\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, dropout_prob=0.5):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_planes = 32\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(dropout_prob)  \n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = Mish()(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = F.dropout(out, p=0.5, training=self.training) \n",
    "        return self.fc(out)\n",
    "\n",
    "def continue_training():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "   \n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.AutoAugment(),\n",
    "        transforms.ToTensor(),          \n",
    "        transforms.RandomErasing(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "    \n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "    \n",
    "    trainset = CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "    trainloader = DataLoader(trainset, batch_size=256, shuffle=True, num_workers=4)\n",
    "    \n",
    "    testset = CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "    testloader = DataLoader(testset, batch_size=256, shuffle=False, num_workers=4)\n",
    "    \n",
    "    model = ResNet18(BasicBlock, [2, 2, 2, 2]).to(device)\n",
    "    model.load_state_dict(torch.load(\"optimized_resnet18.pth\"))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-4)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "    \n",
    "    num_epochs = 200\n",
    "    for epoch in range(1):  \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(trainloader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_train += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        avg_train_loss = train_loss / total_train\n",
    "        train_acc = 100. * train_correct / total_train\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        total_test = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(testloader, desc=f\"Testing Epoch {epoch+1}/{num_epochs}\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_test += labels.size(0)\n",
    "                test_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        avg_test_loss = test_loss / total_test\n",
    "        test_acc = 100. * test_correct / total_test\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"    Training Loss: {avg_train_loss:.4f} | Training Acc: {train_acc:.2f}%\")\n",
    "        print(f\"    Testing Loss: {avg_test_loss:.4f}  | Testing Acc: {test_acc:.2f}%\")\n",
    "        \n",
    "        torch.save(model.state_dict(), \"optimized_resnet18.pth\")\n",
    "    \n",
    "    print(\"\\n Model Summary After Training:\")\n",
    "    summary(model, (3, 32, 32))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    continue_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6563ebc",
   "metadata": {},
   "source": [
    "This block of code was used to continue training the model from where it had left off due to HPC crashing. \n",
    "\n",
    "In our code, we are uploading the model after every epoch. When HPC crashes and we have ro restart out training, then we continue training from the same number of epoch using the latest model. This way we could train the model for 200 epochs over multiple HPC sessions even if HPC crashed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ee922-b92b-4037-b171-7d777b2eec39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 85/200: 100%|██████████| 196/196 [00:15<00:00, 12.85it/s]\n",
      "Testing Epoch 85/200: 100%|██████████| 40/40 [00:00<00:00, 47.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200:\n",
      "    Training Loss: 1.2218 | Training Acc: 73.90%\n",
      "    Testing Loss: 0.8299  | Testing Acc: 86.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 86/200: 100%|██████████| 196/196 [00:12<00:00, 15.37it/s]\n",
      "Testing Epoch 86/200: 100%|██████████| 40/40 [00:00<00:00, 58.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200:\n",
      "    Training Loss: 1.0564 | Training Acc: 79.53%\n",
      "    Testing Loss: 0.8231  | Testing Acc: 86.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 87/200: 100%|██████████| 196/196 [00:13<00:00, 15.00it/s]\n",
      "Testing Epoch 87/200: 100%|██████████| 40/40 [00:00<00:00, 54.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200:\n",
      "    Training Loss: 0.9776 | Training Acc: 81.98%\n",
      "    Testing Loss: 0.7608  | Testing Acc: 89.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 88/200: 100%|██████████| 196/196 [00:12<00:00, 15.12it/s]\n",
      "Testing Epoch 88/200: 100%|██████████| 40/40 [00:00<00:00, 56.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200:\n",
      "    Training Loss: 0.9246 | Training Acc: 83.92%\n",
      "    Testing Loss: 0.7149  | Testing Acc: 90.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 89/200: 100%|██████████| 196/196 [00:13<00:00, 15.08it/s]\n",
      "Testing Epoch 89/200: 100%|██████████| 40/40 [00:00<00:00, 57.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200:\n",
      "    Training Loss: 0.8894 | Training Acc: 85.10%\n",
      "    Testing Loss: 0.7120  | Testing Acc: 90.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 90/200: 100%|██████████| 196/196 [00:12<00:00, 15.41it/s]\n",
      "Testing Epoch 90/200: 100%|██████████| 40/40 [00:00<00:00, 56.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200:\n",
      "    Training Loss: 0.8553 | Training Acc: 86.56%\n",
      "    Testing Loss: 0.6809  | Testing Acc: 92.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 91/200: 100%|██████████| 196/196 [00:12<00:00, 15.09it/s]\n",
      "Testing Epoch 91/200: 100%|██████████| 40/40 [00:00<00:00, 56.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200:\n",
      "    Training Loss: 0.8246 | Training Acc: 87.95%\n",
      "    Testing Loss: 0.6640  | Testing Acc: 92.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 92/200: 100%|██████████| 196/196 [00:13<00:00, 14.90it/s]\n",
      "Testing Epoch 92/200: 100%|██████████| 40/40 [00:00<00:00, 54.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200:\n",
      "    Training Loss: 0.7965 | Training Acc: 89.06%\n",
      "    Testing Loss: 0.6506  | Testing Acc: 93.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 93/200: 100%|██████████| 196/196 [00:12<00:00, 15.46it/s]\n",
      "Testing Epoch 93/200: 100%|██████████| 40/40 [00:00<00:00, 54.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200:\n",
      "    Training Loss: 0.7779 | Training Acc: 89.80%\n",
      "    Testing Loss: 0.6408  | Testing Acc: 94.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 94/200: 100%|██████████| 196/196 [00:12<00:00, 15.30it/s]\n",
      "Testing Epoch 94/200: 100%|██████████| 40/40 [00:00<00:00, 54.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/200:\n",
      "    Training Loss: 0.7687 | Training Acc: 90.25%\n",
      "    Testing Loss: 0.6389  | Testing Acc: 93.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 95/200: 100%|██████████| 196/196 [00:13<00:00, 14.91it/s]\n",
      "Testing Epoch 95/200: 100%|██████████| 40/40 [00:00<00:00, 54.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200:\n",
      "    Training Loss: 0.8915 | Training Acc: 84.81%\n",
      "    Testing Loss: 0.7150  | Testing Acc: 90.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 96/200: 100%|██████████| 196/196 [00:12<00:00, 15.16it/s]\n",
      "Testing Epoch 96/200: 100%|██████████| 40/40 [00:00<00:00, 56.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/200:\n",
      "    Training Loss: 0.8946 | Training Acc: 84.45%\n",
      "    Testing Loss: 0.7353  | Testing Acc: 90.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 97/200: 100%|██████████| 196/196 [00:12<00:00, 15.18it/s]\n",
      "Testing Epoch 97/200: 100%|██████████| 40/40 [00:00<00:00, 56.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/200:\n",
      "    Training Loss: 0.8842 | Training Acc: 84.82%\n",
      "    Testing Loss: 0.7209  | Testing Acc: 90.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 98/200: 100%|██████████| 196/196 [00:13<00:00, 14.59it/s]\n",
      "Testing Epoch 98/200: 100%|██████████| 40/40 [00:00<00:00, 54.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200:\n",
      "    Training Loss: 0.8639 | Training Acc: 85.43%\n",
      "    Testing Loss: 0.7029  | Testing Acc: 91.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 99/200: 100%|██████████| 196/196 [00:12<00:00, 15.20it/s]\n",
      "Testing Epoch 99/200: 100%|██████████| 40/40 [00:00<00:00, 54.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200:\n",
      "    Training Loss: 0.8521 | Training Acc: 86.04%\n",
      "    Testing Loss: 0.6955  | Testing Acc: 91.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 100/200: 100%|██████████| 196/196 [00:12<00:00, 15.60it/s]\n",
      "Testing Epoch 100/200: 100%|██████████| 40/40 [00:00<00:00, 54.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200:\n",
      "    Training Loss: 0.8412 | Training Acc: 86.51%\n",
      "    Testing Loss: 0.6997  | Testing Acc: 91.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 101/200: 100%|██████████| 196/196 [00:12<00:00, 15.62it/s]\n",
      "Testing Epoch 101/200: 100%|██████████| 40/40 [00:00<00:00, 56.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/200:\n",
      "    Training Loss: 0.8266 | Training Acc: 86.96%\n",
      "    Testing Loss: 0.6895  | Testing Acc: 92.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 102/200: 100%|██████████| 196/196 [00:12<00:00, 15.53it/s]\n",
      "Testing Epoch 102/200: 100%|██████████| 40/40 [00:00<00:00, 56.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200:\n",
      "    Training Loss: 0.8181 | Training Acc: 87.29%\n",
      "    Testing Loss: 0.6796  | Testing Acc: 92.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 103/200: 100%|██████████| 196/196 [00:12<00:00, 15.58it/s]\n",
      "Testing Epoch 103/200: 100%|██████████| 40/40 [00:00<00:00, 55.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/200:\n",
      "    Training Loss: 0.7995 | Training Acc: 88.22%\n",
      "    Testing Loss: 0.6784  | Testing Acc: 92.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 104/200: 100%|██████████| 196/196 [00:13<00:00, 15.05it/s]\n",
      "Testing Epoch 104/200: 100%|██████████| 40/40 [00:00<00:00, 55.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/200:\n",
      "    Training Loss: 0.7887 | Training Acc: 88.45%\n",
      "    Testing Loss: 0.6640  | Testing Acc: 93.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 105/200: 100%|██████████| 196/196 [00:12<00:00, 15.49it/s]\n",
      "Testing Epoch 105/200: 100%|██████████| 40/40 [00:00<00:00, 55.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200:\n",
      "    Training Loss: 0.7721 | Training Acc: 89.30%\n",
      "    Testing Loss: 0.6635  | Testing Acc: 92.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 106/200: 100%|██████████| 196/196 [00:12<00:00, 15.52it/s]\n",
      "Testing Epoch 106/200: 100%|██████████| 40/40 [00:00<00:00, 53.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200:\n",
      "    Training Loss: 0.7704 | Training Acc: 89.19%\n",
      "    Testing Loss: 0.6549  | Testing Acc: 93.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 107/200: 100%|██████████| 196/196 [00:12<00:00, 15.53it/s]\n",
      "Testing Epoch 107/200: 100%|██████████| 40/40 [00:00<00:00, 53.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200:\n",
      "    Training Loss: 0.7533 | Training Acc: 89.98%\n",
      "    Testing Loss: 0.6506  | Testing Acc: 93.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 108/200: 100%|██████████| 196/196 [00:12<00:00, 15.11it/s]\n",
      "Testing Epoch 108/200: 100%|██████████| 40/40 [00:00<00:00, 56.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200:\n",
      "    Training Loss: 0.7440 | Training Acc: 90.51%\n",
      "    Testing Loss: 0.6462  | Testing Acc: 93.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 109/200: 100%|██████████| 196/196 [00:12<00:00, 15.47it/s]\n",
      "Testing Epoch 109/200: 100%|██████████| 40/40 [00:00<00:00, 56.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200:\n",
      "    Training Loss: 0.7318 | Training Acc: 91.04%\n",
      "    Testing Loss: 0.6381  | Testing Acc: 94.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 110/200: 100%|██████████| 196/196 [00:12<00:00, 15.47it/s]\n",
      "Testing Epoch 110/200: 100%|██████████| 40/40 [00:00<00:00, 56.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200:\n",
      "    Training Loss: 0.7276 | Training Acc: 91.05%\n",
      "    Testing Loss: 0.6338  | Testing Acc: 94.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 111/200: 100%|██████████| 196/196 [00:12<00:00, 15.46it/s]\n",
      "Testing Epoch 111/200: 100%|██████████| 40/40 [00:00<00:00, 56.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200:\n",
      "    Training Loss: 0.7210 | Training Acc: 91.37%\n",
      "    Testing Loss: 0.6331  | Testing Acc: 94.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 112/200: 100%|██████████| 196/196 [00:13<00:00, 14.94it/s]\n",
      "Testing Epoch 112/200: 100%|██████████| 40/40 [00:00<00:00, 55.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200:\n",
      "    Training Loss: 0.7151 | Training Acc: 91.63%\n",
      "    Testing Loss: 0.6302  | Testing Acc: 94.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 113/200: 100%|██████████| 196/196 [00:12<00:00, 15.21it/s]\n",
      "Testing Epoch 113/200: 100%|██████████| 40/40 [00:00<00:00, 56.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/200:\n",
      "    Training Loss: 0.7072 | Training Acc: 91.97%\n",
      "    Testing Loss: 0.6300  | Testing Acc: 94.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 114/200: 100%|██████████| 196/196 [00:12<00:00, 15.31it/s]\n",
      "Testing Epoch 114/200: 100%|██████████| 40/40 [00:00<00:00, 54.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200:\n",
      "    Training Loss: 0.7109 | Training Acc: 91.90%\n",
      "    Testing Loss: 0.6302  | Testing Acc: 94.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 115/200: 100%|██████████| 196/196 [00:12<00:00, 15.28it/s]\n",
      "Testing Epoch 115/200: 100%|██████████| 40/40 [00:00<00:00, 54.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200:\n",
      "    Training Loss: 0.8180 | Training Acc: 87.00%\n",
      "    Testing Loss: 0.6886  | Testing Acc: 92.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 116/200: 100%|██████████| 196/196 [00:13<00:00, 14.99it/s]\n",
      "Testing Epoch 116/200: 100%|██████████| 40/40 [00:00<00:00, 53.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200:\n",
      "    Training Loss: 0.8218 | Training Acc: 86.86%\n",
      "    Testing Loss: 0.6954  | Testing Acc: 91.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 117/200: 100%|██████████| 196/196 [00:12<00:00, 15.29it/s]\n",
      "Testing Epoch 117/200: 100%|██████████| 40/40 [00:00<00:00, 56.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200:\n",
      "    Training Loss: 0.8231 | Training Acc: 86.81%\n",
      "    Testing Loss: 0.6986  | Testing Acc: 91.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 118/200: 100%|██████████| 196/196 [00:12<00:00, 15.23it/s]\n",
      "Testing Epoch 118/200: 100%|██████████| 40/40 [00:00<00:00, 57.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200:\n",
      "    Training Loss: 0.8146 | Training Acc: 87.27%\n",
      "    Testing Loss: 0.6866  | Testing Acc: 92.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 119/200: 100%|██████████| 196/196 [00:12<00:00, 15.45it/s]\n",
      "Testing Epoch 119/200: 100%|██████████| 40/40 [00:00<00:00, 57.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200:\n",
      "    Training Loss: 0.8107 | Training Acc: 87.32%\n",
      "    Testing Loss: 0.6944  | Testing Acc: 91.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 120/200: 100%|██████████| 196/196 [00:12<00:00, 15.28it/s]\n",
      "Testing Epoch 120/200: 100%|██████████| 40/40 [00:00<00:00, 56.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200:\n",
      "    Training Loss: 0.8007 | Training Acc: 87.82%\n",
      "    Testing Loss: 0.7004  | Testing Acc: 91.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 121/200: 100%|██████████| 196/196 [00:12<00:00, 15.44it/s]\n",
      "Testing Epoch 121/200: 100%|██████████| 40/40 [00:00<00:00, 54.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200:\n",
      "    Training Loss: 0.7989 | Training Acc: 87.71%\n",
      "    Testing Loss: 0.6943  | Testing Acc: 91.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 122/200: 100%|██████████| 196/196 [00:12<00:00, 15.54it/s]\n",
      "Testing Epoch 122/200: 100%|██████████| 40/40 [00:00<00:00, 55.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200:\n",
      "    Training Loss: 0.7984 | Training Acc: 87.80%\n",
      "    Testing Loss: 0.6771  | Testing Acc: 92.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 123/200: 100%|██████████| 196/196 [00:12<00:00, 15.50it/s]\n",
      "Testing Epoch 123/200: 100%|██████████| 40/40 [00:00<00:00, 55.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200:\n",
      "    Training Loss: 0.7908 | Training Acc: 88.11%\n",
      "    Testing Loss: 0.6790  | Testing Acc: 92.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 124/200: 100%|██████████| 196/196 [00:13<00:00, 14.88it/s]\n",
      "Testing Epoch 124/200: 100%|██████████| 40/40 [00:00<00:00, 54.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200:\n",
      "    Training Loss: 0.7854 | Training Acc: 88.21%\n",
      "    Testing Loss: 0.6826  | Testing Acc: 92.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 125/200: 100%|██████████| 196/196 [00:13<00:00, 15.03it/s]\n",
      "Testing Epoch 125/200: 100%|██████████| 40/40 [00:00<00:00, 57.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200:\n",
      "    Training Loss: 0.7799 | Training Acc: 88.62%\n",
      "    Testing Loss: 0.6587  | Testing Acc: 93.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 126/200: 100%|██████████| 196/196 [00:13<00:00, 15.03it/s]\n",
      "Testing Epoch 126/200: 100%|██████████| 40/40 [00:00<00:00, 56.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/200:\n",
      "    Training Loss: 0.7753 | Training Acc: 88.70%\n",
      "    Testing Loss: 0.6924  | Testing Acc: 91.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 127/200: 100%|██████████| 196/196 [00:12<00:00, 15.30it/s]\n",
      "Testing Epoch 127/200: 100%|██████████| 40/40 [00:00<00:00, 53.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200:\n",
      "    Training Loss: 0.7734 | Training Acc: 88.82%\n",
      "    Testing Loss: 0.6673  | Testing Acc: 92.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 128/200: 100%|██████████| 196/196 [00:13<00:00, 15.00it/s]\n",
      "Testing Epoch 128/200: 100%|██████████| 40/40 [00:00<00:00, 55.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/200:\n",
      "    Training Loss: 0.7670 | Training Acc: 89.04%\n",
      "    Testing Loss: 0.6524  | Testing Acc: 93.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 129/200: 100%|██████████| 196/196 [00:13<00:00, 14.98it/s]\n",
      "Testing Epoch 129/200: 100%|██████████| 40/40 [00:00<00:00, 54.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/200:\n",
      "    Training Loss: 0.7623 | Training Acc: 89.30%\n",
      "    Testing Loss: 0.6629  | Testing Acc: 93.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 130/200: 100%|██████████| 196/196 [00:12<00:00, 15.61it/s]\n",
      "Testing Epoch 130/200: 100%|██████████| 40/40 [00:00<00:00, 54.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200:\n",
      "    Training Loss: 0.7535 | Training Acc: 89.63%\n",
      "    Testing Loss: 0.6584  | Testing Acc: 93.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 131/200: 100%|██████████| 196/196 [00:12<00:00, 15.11it/s]\n",
      "Testing Epoch 131/200: 100%|██████████| 40/40 [00:00<00:00, 55.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/200:\n",
      "    Training Loss: 0.7484 | Training Acc: 89.84%\n",
      "    Testing Loss: 0.6534  | Testing Acc: 93.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 132/200: 100%|██████████| 196/196 [00:12<00:00, 15.53it/s]\n",
      "Testing Epoch 132/200: 100%|██████████| 40/40 [00:00<00:00, 56.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200:\n",
      "    Training Loss: 0.7465 | Training Acc: 89.98%\n",
      "    Testing Loss: 0.6597  | Testing Acc: 93.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 133/200: 100%|██████████| 196/196 [00:12<00:00, 15.33it/s]\n",
      "Testing Epoch 133/200: 100%|██████████| 40/40 [00:00<00:00, 56.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/200:\n",
      "    Training Loss: 0.7373 | Training Acc: 90.38%\n",
      "    Testing Loss: 0.6498  | Testing Acc: 93.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 134/200: 100%|██████████| 196/196 [00:12<00:00, 15.44it/s]\n",
      "Testing Epoch 134/200: 100%|██████████| 40/40 [00:00<00:00, 56.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/200:\n",
      "    Training Loss: 0.7321 | Training Acc: 90.47%\n",
      "    Testing Loss: 0.6529  | Testing Acc: 93.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 135/200: 100%|██████████| 196/196 [00:13<00:00, 15.05it/s]\n",
      "Testing Epoch 135/200: 100%|██████████| 40/40 [00:00<00:00, 55.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200:\n",
      "    Training Loss: 0.7272 | Training Acc: 90.68%\n",
      "    Testing Loss: 0.6539  | Testing Acc: 93.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 136/200: 100%|██████████| 196/196 [00:13<00:00, 15.04it/s]\n",
      "Testing Epoch 136/200: 100%|██████████| 40/40 [00:00<00:00, 55.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/200:\n",
      "    Training Loss: 0.7231 | Training Acc: 90.98%\n",
      "    Testing Loss: 0.6481  | Testing Acc: 94.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 137/200: 100%|██████████| 196/196 [00:12<00:00, 15.34it/s]\n",
      "Testing Epoch 137/200: 100%|██████████| 40/40 [00:00<00:00, 55.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/200:\n",
      "    Training Loss: 0.7248 | Training Acc: 90.94%\n",
      "    Testing Loss: 0.6342  | Testing Acc: 94.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 138/200: 100%|██████████| 196/196 [00:13<00:00, 14.86it/s]\n",
      "Testing Epoch 138/200: 100%|██████████| 40/40 [00:00<00:00, 56.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/200:\n",
      "    Training Loss: 0.7173 | Training Acc: 91.22%\n",
      "    Testing Loss: 0.6356  | Testing Acc: 94.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 139/200: 100%|██████████| 196/196 [00:12<00:00, 15.57it/s]\n",
      "Testing Epoch 139/200: 100%|██████████| 40/40 [00:00<00:00, 56.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/200:\n",
      "    Training Loss: 0.7085 | Training Acc: 91.52%\n",
      "    Testing Loss: 0.6413  | Testing Acc: 94.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 140/200: 100%|██████████| 196/196 [00:12<00:00, 15.64it/s]\n",
      "Testing Epoch 140/200: 100%|██████████| 40/40 [00:00<00:00, 55.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200:\n",
      "    Training Loss: 0.7032 | Training Acc: 91.76%\n",
      "    Testing Loss: 0.6359  | Testing Acc: 94.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 141/200: 100%|██████████| 196/196 [00:12<00:00, 15.58it/s]\n",
      "Testing Epoch 141/200: 100%|██████████| 40/40 [00:00<00:00, 56.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200:\n",
      "    Training Loss: 0.7041 | Training Acc: 91.79%\n",
      "    Testing Loss: 0.6343  | Testing Acc: 94.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 142/200: 100%|██████████| 196/196 [00:13<00:00, 15.00it/s]\n",
      "Testing Epoch 142/200: 100%|██████████| 40/40 [00:00<00:00, 56.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200:\n",
      "    Training Loss: 0.6994 | Training Acc: 91.98%\n",
      "    Testing Loss: 0.6359  | Testing Acc: 94.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 143/200: 100%|██████████| 196/196 [00:12<00:00, 15.32it/s]\n",
      "Testing Epoch 143/200: 100%|██████████| 40/40 [00:00<00:00, 54.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/200:\n",
      "    Training Loss: 0.6928 | Training Acc: 92.28%\n",
      "    Testing Loss: 0.6337  | Testing Acc: 94.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 144/200: 100%|██████████| 196/196 [00:12<00:00, 15.54it/s]\n",
      "Testing Epoch 144/200: 100%|██████████| 40/40 [00:00<00:00, 56.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/200:\n",
      "    Training Loss: 0.6907 | Training Acc: 92.41%\n",
      "    Testing Loss: 0.6276  | Testing Acc: 94.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 145/200: 100%|██████████| 196/196 [00:12<00:00, 15.51it/s]\n",
      "Testing Epoch 145/200: 100%|██████████| 40/40 [00:00<00:00, 56.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200:\n",
      "    Training Loss: 0.6855 | Training Acc: 92.62%\n",
      "    Testing Loss: 0.6296  | Testing Acc: 94.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 146/200: 100%|██████████| 196/196 [00:12<00:00, 15.54it/s]\n",
      "Testing Epoch 146/200: 100%|██████████| 40/40 [00:00<00:00, 56.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/200:\n",
      "    Training Loss: 0.6803 | Training Acc: 92.82%\n",
      "    Testing Loss: 0.6240  | Testing Acc: 94.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 147/200: 100%|██████████| 196/196 [00:12<00:00, 15.50it/s]\n",
      "Testing Epoch 147/200: 100%|██████████| 40/40 [00:00<00:00, 56.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/200:\n",
      "    Training Loss: 0.6817 | Training Acc: 92.81%\n",
      "    Testing Loss: 0.6249  | Testing Acc: 94.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 148/200: 100%|██████████| 196/196 [00:13<00:00, 14.94it/s]\n",
      "Testing Epoch 148/200: 100%|██████████| 40/40 [00:00<00:00, 56.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200:\n",
      "    Training Loss: 0.6760 | Training Acc: 92.97%\n",
      "    Testing Loss: 0.6258  | Testing Acc: 94.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 149/200: 100%|██████████| 196/196 [00:12<00:00, 15.58it/s]\n",
      "Testing Epoch 149/200: 100%|██████████| 40/40 [00:00<00:00, 55.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/200:\n",
      "    Training Loss: 0.6755 | Training Acc: 92.94%\n",
      "    Testing Loss: 0.6259  | Testing Acc: 94.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 150/200: 100%|██████████| 196/196 [00:13<00:00, 15.07it/s]\n",
      "Testing Epoch 150/200: 100%|██████████| 40/40 [00:00<00:00, 56.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/200:\n",
      "    Training Loss: 0.6745 | Training Acc: 93.15%\n",
      "    Testing Loss: 0.6237  | Testing Acc: 94.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 151/200: 100%|██████████| 196/196 [00:12<00:00, 15.22it/s]\n",
      "Testing Epoch 151/200: 100%|██████████| 40/40 [00:00<00:00, 52.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/200:\n",
      "    Training Loss: 0.6713 | Training Acc: 93.20%\n",
      "    Testing Loss: 0.6251  | Testing Acc: 94.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 152/200: 100%|██████████| 196/196 [00:13<00:00, 15.08it/s]\n",
      "Testing Epoch 152/200: 100%|██████████| 40/40 [00:00<00:00, 55.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/200:\n",
      "    Training Loss: 0.6687 | Training Acc: 93.44%\n",
      "    Testing Loss: 0.6227  | Testing Acc: 94.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 153/200: 100%|██████████| 196/196 [00:12<00:00, 15.27it/s]\n",
      "Testing Epoch 153/200: 100%|██████████| 40/40 [00:00<00:00, 54.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/200:\n",
      "    Training Loss: 0.6682 | Training Acc: 93.26%\n",
      "    Testing Loss: 0.6236  | Testing Acc: 94.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 154/200: 100%|██████████| 196/196 [00:12<00:00, 15.54it/s]\n",
      "Testing Epoch 154/200: 100%|██████████| 40/40 [00:00<00:00, 56.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/200:\n",
      "    Training Loss: 0.6693 | Training Acc: 93.26%\n",
      "    Testing Loss: 0.6238  | Testing Acc: 94.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 155/200: 100%|██████████| 196/196 [00:12<00:00, 15.54it/s]\n",
      "Testing Epoch 155/200: 100%|██████████| 40/40 [00:00<00:00, 56.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200:\n",
      "    Training Loss: 0.7682 | Training Acc: 88.90%\n",
      "    Testing Loss: 0.6790  | Testing Acc: 92.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 156/200: 100%|██████████| 196/196 [00:12<00:00, 15.41it/s]\n",
      "Testing Epoch 156/200: 100%|██████████| 40/40 [00:00<00:00, 57.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/200:\n",
      "    Training Loss: 0.7777 | Training Acc: 88.41%\n",
      "    Testing Loss: 0.6908  | Testing Acc: 92.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 157/200: 100%|██████████| 196/196 [00:12<00:00, 15.63it/s]\n",
      "Testing Epoch 157/200: 100%|██████████| 40/40 [00:00<00:00, 54.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/200:\n",
      "    Training Loss: 0.7768 | Training Acc: 88.42%\n",
      "    Testing Loss: 0.6826  | Testing Acc: 92.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 158/200: 100%|██████████| 196/196 [00:12<00:00, 15.56it/s]\n",
      "Testing Epoch 158/200: 100%|██████████| 40/40 [00:00<00:00, 54.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/200:\n",
      "    Training Loss: 0.7786 | Training Acc: 88.40%\n",
      "    Testing Loss: 0.6759  | Testing Acc: 92.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 159/200: 100%|██████████| 196/196 [00:12<00:00, 15.49it/s]\n",
      "Testing Epoch 159/200: 100%|██████████| 40/40 [00:00<00:00, 56.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/200:\n",
      "    Training Loss: 0.7726 | Training Acc: 88.59%\n",
      "    Testing Loss: 0.6752  | Testing Acc: 92.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 160/200: 100%|██████████| 196/196 [00:12<00:00, 15.53it/s]\n",
      "Testing Epoch 160/200: 100%|██████████| 40/40 [00:00<00:00, 55.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200:\n",
      "    Training Loss: 0.7698 | Training Acc: 88.70%\n",
      "    Testing Loss: 0.6792  | Testing Acc: 92.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 161/200: 100%|██████████| 196/196 [00:12<00:00, 15.44it/s]\n",
      "Testing Epoch 161/200: 100%|██████████| 40/40 [00:00<00:00, 55.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200:\n",
      "    Training Loss: 0.7705 | Training Acc: 88.81%\n",
      "    Testing Loss: 0.6654  | Testing Acc: 93.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 162/200: 100%|██████████| 196/196 [00:12<00:00, 15.48it/s]\n",
      "Testing Epoch 162/200: 100%|██████████| 40/40 [00:00<00:00, 54.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/200:\n",
      "    Training Loss: 0.7673 | Training Acc: 89.03%\n",
      "    Testing Loss: 0.6758  | Testing Acc: 92.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 163/200: 100%|██████████| 196/196 [00:12<00:00, 15.59it/s]\n",
      "Testing Epoch 163/200: 100%|██████████| 40/40 [00:00<00:00, 56.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/200:\n",
      "    Training Loss: 0.7656 | Training Acc: 88.89%\n",
      "    Testing Loss: 0.6739  | Testing Acc: 92.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 164/200: 100%|██████████| 196/196 [00:13<00:00, 15.02it/s]\n",
      "Testing Epoch 164/200: 100%|██████████| 40/40 [00:00<00:00, 56.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/200:\n",
      "    Training Loss: 0.7631 | Training Acc: 89.01%\n",
      "    Testing Loss: 0.6726  | Testing Acc: 92.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 165/200: 100%|██████████| 196/196 [00:12<00:00, 15.52it/s]\n",
      "Testing Epoch 165/200: 100%|██████████| 40/40 [00:00<00:00, 54.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/200:\n",
      "    Training Loss: 0.7612 | Training Acc: 89.19%\n",
      "    Testing Loss: 0.6717  | Testing Acc: 92.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 166/200: 100%|██████████| 196/196 [00:13<00:00, 15.05it/s]\n",
      "Testing Epoch 166/200: 100%|██████████| 40/40 [00:00<00:00, 55.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/200:\n",
      "    Training Loss: 0.7571 | Training Acc: 89.31%\n",
      "    Testing Loss: 0.6642  | Testing Acc: 93.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 167/200: 100%|██████████| 196/196 [00:12<00:00, 15.38it/s]\n",
      "Testing Epoch 167/200: 100%|██████████| 40/40 [00:00<00:00, 56.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200:\n",
      "    Training Loss: 0.7595 | Training Acc: 89.29%\n",
      "    Testing Loss: 0.6597  | Testing Acc: 93.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 168/200: 100%|██████████| 196/196 [00:12<00:00, 15.15it/s]\n",
      "Testing Epoch 168/200: 100%|██████████| 40/40 [00:00<00:00, 53.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/200:\n",
      "    Training Loss: 0.7555 | Training Acc: 89.26%\n",
      "    Testing Loss: 0.6579  | Testing Acc: 93.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 169/200: 100%|██████████| 196/196 [00:13<00:00, 15.06it/s]\n",
      "Testing Epoch 169/200: 100%|██████████| 40/40 [00:00<00:00, 55.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200:\n",
      "    Training Loss: 0.7563 | Training Acc: 89.25%\n",
      "    Testing Loss: 0.6755  | Testing Acc: 92.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 170/200: 100%|██████████| 196/196 [00:12<00:00, 15.47it/s]\n",
      "Testing Epoch 170/200: 100%|██████████| 40/40 [00:00<00:00, 56.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200:\n",
      "    Training Loss: 0.7533 | Training Acc: 89.42%\n",
      "    Testing Loss: 0.6633  | Testing Acc: 93.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 171/200: 100%|██████████| 196/196 [00:12<00:00, 15.54it/s]\n",
      "Testing Epoch 171/200: 100%|██████████| 40/40 [00:00<00:00, 56.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200:\n",
      "    Training Loss: 0.7529 | Training Acc: 89.32%\n",
      "    Testing Loss: 0.6624  | Testing Acc: 92.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 172/200: 100%|██████████| 196/196 [00:12<00:00, 15.54it/s]\n",
      "Testing Epoch 172/200: 100%|██████████| 40/40 [00:00<00:00, 56.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200:\n",
      "    Training Loss: 0.7447 | Training Acc: 89.76%\n",
      "    Testing Loss: 0.6612  | Testing Acc: 93.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 173/200: 100%|██████████| 196/196 [00:12<00:00, 15.49it/s]\n",
      "Testing Epoch 173/200: 100%|██████████| 40/40 [00:00<00:00, 56.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200:\n",
      "    Training Loss: 0.7456 | Training Acc: 89.70%\n",
      "    Testing Loss: 0.6729  | Testing Acc: 92.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 174/200: 100%|██████████| 196/196 [00:12<00:00, 15.50it/s]\n",
      "Testing Epoch 174/200: 100%|██████████| 40/40 [00:00<00:00, 56.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/200:\n",
      "    Training Loss: 0.7456 | Training Acc: 89.71%\n",
      "    Testing Loss: 0.6525  | Testing Acc: 93.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 175/200: 100%|██████████| 196/196 [00:12<00:00, 15.51it/s]\n",
      "Testing Epoch 175/200: 100%|██████████| 40/40 [00:00<00:00, 55.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200:\n",
      "    Training Loss: 0.7393 | Training Acc: 89.94%\n",
      "    Testing Loss: 0.6632  | Testing Acc: 93.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 176/200: 100%|██████████| 196/196 [00:12<00:00, 15.20it/s]\n",
      "Testing Epoch 176/200: 100%|██████████| 40/40 [00:00<00:00, 55.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/200:\n",
      "    Training Loss: 0.7395 | Training Acc: 90.13%\n",
      "    Testing Loss: 0.6609  | Testing Acc: 93.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 177/200: 100%|██████████| 196/196 [00:12<00:00, 15.57it/s]\n",
      "Testing Epoch 177/200: 100%|██████████| 40/40 [00:00<00:00, 56.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/200:\n",
      "    Training Loss: 0.7377 | Training Acc: 90.02%\n",
      "    Testing Loss: 0.6593  | Testing Acc: 93.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 178/200: 100%|██████████| 196/196 [00:13<00:00, 14.94it/s]\n",
      "Testing Epoch 178/200: 100%|██████████| 40/40 [00:00<00:00, 55.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/200:\n",
      "    Training Loss: 0.7370 | Training Acc: 90.14%\n",
      "    Testing Loss: 0.6550  | Testing Acc: 93.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 179/200: 100%|██████████| 196/196 [00:12<00:00, 15.60it/s]\n",
      "Testing Epoch 179/200: 100%|██████████| 40/40 [00:00<00:00, 56.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/200:\n",
      "    Training Loss: 0.7315 | Training Acc: 90.34%\n",
      "    Testing Loss: 0.6513  | Testing Acc: 93.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 180/200: 100%|██████████| 196/196 [00:12<00:00, 15.21it/s]\n",
      "Testing Epoch 180/200: 100%|██████████| 40/40 [00:00<00:00, 57.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200:\n",
      "    Training Loss: 0.7373 | Training Acc: 90.06%\n",
      "    Testing Loss: 0.6461  | Testing Acc: 93.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 181/200: 100%|██████████| 196/196 [00:12<00:00, 15.15it/s]\n",
      "Testing Epoch 181/200: 100%|██████████| 40/40 [00:00<00:00, 56.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200:\n",
      "    Training Loss: 0.7333 | Training Acc: 90.33%\n",
      "    Testing Loss: 0.6554  | Testing Acc: 93.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 182/200: 100%|██████████| 196/196 [00:12<00:00, 15.52it/s]\n",
      "Testing Epoch 182/200: 100%|██████████| 40/40 [00:00<00:00, 56.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/200:\n",
      "    Training Loss: 0.7292 | Training Acc: 90.36%\n",
      "    Testing Loss: 0.6578  | Testing Acc: 93.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 183/200: 100%|██████████| 196/196 [00:12<00:00, 15.51it/s]\n",
      "Testing Epoch 183/200: 100%|██████████| 40/40 [00:00<00:00, 53.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200:\n",
      "    Training Loss: 0.7250 | Training Acc: 90.58%\n",
      "    Testing Loss: 0.6541  | Testing Acc: 93.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 184/200: 100%|██████████| 196/196 [00:13<00:00, 15.07it/s]\n",
      "Testing Epoch 184/200: 100%|██████████| 40/40 [00:00<00:00, 56.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/200:\n",
      "    Training Loss: 0.7263 | Training Acc: 90.64%\n",
      "    Testing Loss: 0.6485  | Testing Acc: 93.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 185/200: 100%|██████████| 196/196 [00:13<00:00, 14.83it/s]\n",
      "Testing Epoch 185/200: 100%|██████████| 40/40 [00:00<00:00, 56.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/200:\n",
      "    Training Loss: 0.7250 | Training Acc: 90.65%\n",
      "    Testing Loss: 0.6464  | Testing Acc: 93.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 186/200: 100%|██████████| 196/196 [00:12<00:00, 15.48it/s]\n",
      "Testing Epoch 186/200: 100%|██████████| 40/40 [00:00<00:00, 54.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/200:\n",
      "    Training Loss: 0.7169 | Training Acc: 91.05%\n",
      "    Testing Loss: 0.6521  | Testing Acc: 93.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 187/200: 100%|██████████| 196/196 [00:12<00:00, 15.50it/s]\n",
      "Testing Epoch 187/200: 100%|██████████| 40/40 [00:00<00:00, 53.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/200:\n",
      "    Training Loss: 0.7171 | Training Acc: 91.17%\n",
      "    Testing Loss: 0.6424  | Testing Acc: 94.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 188/200: 100%|██████████| 196/196 [00:12<00:00, 15.50it/s]\n",
      "Testing Epoch 188/200: 100%|██████████| 40/40 [00:00<00:00, 55.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/200:\n",
      "    Training Loss: 0.7205 | Training Acc: 90.93%\n",
      "    Testing Loss: 0.6447  | Testing Acc: 93.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 189/200: 100%|██████████| 196/196 [00:13<00:00, 15.03it/s]\n",
      "Testing Epoch 189/200: 100%|██████████| 40/40 [00:00<00:00, 56.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/200:\n",
      "    Training Loss: 0.7092 | Training Acc: 91.36%\n",
      "    Testing Loss: 0.6459  | Testing Acc: 93.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 190/200: 100%|██████████| 196/196 [00:12<00:00, 15.46it/s]\n",
      "Testing Epoch 190/200: 100%|██████████| 40/40 [00:00<00:00, 55.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/200:\n",
      "    Training Loss: 0.7085 | Training Acc: 91.33%\n",
      "    Testing Loss: 0.6384  | Testing Acc: 94.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 191/200: 100%|██████████| 196/196 [00:12<00:00, 15.57it/s]\n",
      "Testing Epoch 191/200: 100%|██████████| 40/40 [00:00<00:00, 57.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/200:\n",
      "    Training Loss: 0.7103 | Training Acc: 91.28%\n",
      "    Testing Loss: 0.6445  | Testing Acc: 93.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 192/200: 100%|██████████| 196/196 [00:12<00:00, 15.51it/s]\n",
      "Testing Epoch 192/200: 100%|██████████| 40/40 [00:00<00:00, 56.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/200:\n",
      "    Training Loss: 0.7080 | Training Acc: 91.37%\n",
      "    Testing Loss: 0.6454  | Testing Acc: 93.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 193/200:  21%|██        | 41/196 [00:03<00:12, 12.79it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.tanh(F.softplus(x))\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // reduction, 1),\n",
    "            Mish(),\n",
    "            nn.Conv2d(channels // reduction, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.se(x)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.se = SEBlock(planes)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = Mish()(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.se(out)\n",
    "        out += self.shortcut(x)\n",
    "        return Mish()(out)\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, dropout_prob=0.5):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_planes = 32\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(dropout_prob)  \n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = Mish()(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = F.dropout(out, p=0.5, training=self.training) \n",
    "        return self.fc(out)\n",
    "\n",
    "def continue_training():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "   \n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.AutoAugment(),\n",
    "        transforms.ToTensor(),          \n",
    "        transforms.RandomErasing(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "    \n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "    \n",
    "    trainset = CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "    trainloader = DataLoader(trainset, batch_size=256, shuffle=True, num_workers=4)\n",
    "    \n",
    "    testset = CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "    testloader = DataLoader(testset, batch_size=256, shuffle=False, num_workers=4)\n",
    "    \n",
    "    model = ResNet18(BasicBlock, [2, 2, 2, 2]).to(device)\n",
    "    model.load_state_dict(torch.load(\"optimized_resnet18.pth\"))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-4)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "    \n",
    "    num_epochs = 200\n",
    "    for epoch in range(84,200):  \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(trainloader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_train += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        avg_train_loss = train_loss / total_train\n",
    "        train_acc = 100. * train_correct / total_train\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        test_correct = 0\n",
    "        total_test = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(testloader, desc=f\"Testing Epoch {epoch+1}/{num_epochs}\"):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_test += labels.size(0)\n",
    "                test_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        avg_test_loss = test_loss / total_test\n",
    "        test_acc = 100. * test_correct / total_test\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"    Training Loss: {avg_train_loss:.4f} | Training Acc: {train_acc:.2f}%\")\n",
    "        print(f\"    Testing Loss: {avg_test_loss:.4f}  | Testing Acc: {test_acc:.2f}%\")\n",
    "        \n",
    "        torch.save(model.state_dict(), \"optimized_resnet18.pth\")\n",
    "    \n",
    "    print(\"\\n Model Summary After Training:\")\n",
    "    summary(model, (3, 32, 32))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    continue_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982bd47a-5346-48c5-90d2-2d27757c7493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
